# Cyberbullying-detection-using-Transformer-model-and-XAI
#ðŸ“¢ Cyberbullying Detection with Explainable AI

#ðŸš€ Overview

Cyberbullying is a growing concern in online platforms, affecting individuals of all ages and backgrounds. Harmful online interactions can lead to severe psychological distress, making it crucial to detect and mitigate cyberbullying effectively.

This project leverages advanced Natural Language Processing (NLP) models, including ALBERT, BERT, and RoBERTa, to classify and detect cyberbullying in text-based communications. These transformer-based models offer a balance of efficiency, accuracy, and scalability, making them well-suited for real-time detection in various online environments.

Additionally, this project integrates Explainable AI (XAI) techniques, ensuring transparency in model predictions. By employing interpretability methods such as SHAP (Shapley Additive Explanations) and LIME (Local Interpretable Model-Agnostic Explanations), we can highlight key words and phrases that contribute to the classification decision. This enables a deeper understanding of cyberbullying patterns and helps in refining detection strategies.

Through comprehensive Exploratory Data Analysis (EDA) and visualization techniques, we uncover patterns in online harassment, identify frequently targeted groups, and optimize our model's performance. Our goal is to enhance the safety of digital spaces by making AI-powered cyberbullying detection both accurate and understandable for end users.
